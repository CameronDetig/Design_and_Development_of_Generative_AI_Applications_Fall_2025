{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adapted from: https://github.com/NirDiamant/RAG_Techniques/tree/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypothetical Document Embedding (HyDE) in Document Retrieval\n",
        "\n",
        "## Overview\n",
        "\n",
        "This code implements a Hypothetical Document Embedding (HyDE) system for document retrieval. HyDE is an innovative approach that transforms query questions into hypothetical documents containing the answer, aiming to bridge the gap between query and document distributions in vector space.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Traditional retrieval methods often struggle with the semantic gap between short queries and longer, more detailed documents. HyDE addresses this by expanding the query into a full hypothetical document, potentially improving retrieval relevance by making the query representation more similar to the document representations in the vector space.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. PDF processing and text chunking\n",
        "2. Vector store creation using FAISS and OpenAI embeddings\n",
        "3. Language model for generating hypothetical documents\n",
        "4. Custom HyDERetriever class implementing the HyDE technique\n",
        "\n",
        "## Method Details\n",
        "\n",
        "### Document Preprocessing and Vector Store Creation\n",
        "\n",
        "1. The PDF is processed and split into chunks.\n",
        "2. A FAISS vector store is created using OpenAI embeddings for efficient similarity search.\n",
        "\n",
        "### Hypothetical Document Generation\n",
        "\n",
        "1. A language model (GPT-4) is used to generate a hypothetical document that answers the given query.\n",
        "2. The generation is guided by a prompt template that ensures the hypothetical document is detailed and matches the chunk size used in the vector store.\n",
        "\n",
        "### Retrieval Process\n",
        "\n",
        "The `HyDERetriever` class implements the following steps:\n",
        "\n",
        "1. Generate a hypothetical document from the query using the language model.\n",
        "2. Use the hypothetical document as the search query in the vector store.\n",
        "3. Retrieve the most similar documents to this hypothetical document.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "1. Query Expansion: Transforms short queries into detailed hypothetical documents.\n",
        "2. Flexible Configuration: Allows adjustment of chunk size, overlap, and number of retrieved documents.\n",
        "3. Integration with OpenAI Models: Uses GPT-4 for hypothetical document generation and OpenAI embeddings for vector representation.\n",
        "\n",
        "## Benefits of this Approach\n",
        "\n",
        "1. Improved Relevance: By expanding queries into full documents, HyDE can potentially capture more nuanced and relevant matches.\n",
        "2. Handling Complex Queries: Particularly useful for complex or multi-faceted queries that might be difficult to match directly.\n",
        "3. Adaptability: The hypothetical document generation can adapt to different types of queries and document domains.\n",
        "4. Potential for Better Context Understanding: The expanded query might better capture the context and intent behind the original question.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "1. Uses OpenAI's ChatGPT model for hypothetical document generation.\n",
        "2. Employs FAISS for efficient similarity search in the vector space.\n",
        "3. Allows for easy visualization of both the hypothetical document and retrieved results.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Hypothetical Document Embedding (HyDE) represents an innovative approach to document retrieval, addressing the semantic gap between queries and documents. By leveraging advanced language models to expand queries into hypothetical documents, HyDE has the potential to significantly improve retrieval relevance, especially for complex or nuanced queries. This technique could be particularly valuable in domains where understanding query intent and context is crucial, such as legal research, academic literature review, or advanced information retrieval systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install langchain numpy python-dotenv langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import textwrap\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the OpenAI API key environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "def replace_t_with_space(list_of_documents):\n",
        "    \"\"\"\n",
        "    Replaces all tab characters ('\\t') with spaces in the page content of each document\n",
        "\n",
        "    Args:\n",
        "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
        "\n",
        "    Returns:\n",
        "        The modified list of documents with tab characters replaced by spaces.\n",
        "    \"\"\"\n",
        "\n",
        "    for doc in list_of_documents:\n",
        "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
        "    return list_of_documents\n",
        "\n",
        "def text_wrap(text, width=120):\n",
        "    \"\"\"\n",
        "    Wraps the input text to the specified width.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to wrap.\n",
        "        width (int): The width at which to wrap the text.\n",
        "\n",
        "    Returns:\n",
        "        str: The wrapped text.\n",
        "    \"\"\"\n",
        "    return textwrap.fill(text, width=width)\n",
        "\n",
        "def show_context(context):\n",
        "    \"\"\"\n",
        "    Display the contents of the provided context list.\n",
        "\n",
        "    Args:\n",
        "        context (list): A list of context items to be displayed.\n",
        "\n",
        "    Prints each context item in the list with a heading indicating its position.\n",
        "    \"\"\"\n",
        "    for i, c in enumerate(context):\n",
        "        print(f\"Context {i + 1}:\")\n",
        "        print(c)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define document(s) path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the HyDe retriever class - creating vector store, generating hypothetical document, and retrieving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyDERetriever:\n",
        "    def __init__(self, files_path, chunk_size=500, chunk_overlap=100):\n",
        "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
        "\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.vectorstore = encode_pdf(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
        "    \n",
        "        \n",
        "        self.hyde_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\", \"chunk_size\"],\n",
        "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
        "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
        "        )\n",
        "        self.hyde_chain = self.hyde_prompt | self.llm\n",
        "\n",
        "    def generate_hypothetical_document(self, query):\n",
        "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
        "        return self.hyde_chain.invoke(input_variables).content\n",
        "\n",
        "    def retrieve(self, query, k=3):\n",
        "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
        "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
        "        return similar_docs, hypothetical_doc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a HyDe retriever instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = HyDERetriever(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demonstrate on a use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_query = \"What is the main cause of climate change?\"\n",
        "results, hypothetical_doc = retriever.retrieve(test_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the hypothetical document and the retrieved documnets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hypothetical_doc:\n",
            "\n",
            "**The Main Cause of Climate Change**  Climate change primarily results from human activities, particularly the burning\n",
            "of fossil fuels such as coal, oil, and natural gas. This process releases significant amounts of greenhouse gases\n",
            "(GHGs), notably carbon dioxide (CO2) and methane (CH4), into the atmosphere. Deforestation exacerbates the issue by\n",
            "reducing the number of trees that can absorb CO2. Industrial processes, agriculture, and waste management also\n",
            "contribute to GHG emissions. The accumulation of these gases traps heat, leading to global warming and subsequent\n",
            "climate disruptions, including extreme weather events and rising sea levels.\n",
            "\n",
            "Context 1:\n",
            "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
            "driven by human activities, particularly the emission of greenhouse gases. \n",
            "Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential\n",
            "\n",
            "\n",
            "Context 2:\n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
            "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
            "activities have intensified this natural process, leading to a warmer climate. \n",
            "Fossil Fuels \n",
            "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
            "natural gas used for electricity, heating, and transportation. The industrial revolution marked\n",
            "\n",
            "\n",
            "Context 3:\n",
            "Understanding Climate Change \n",
            "Chapter 1: Introduction to Climate Change \n",
            "Climate change refers to significant, long-term changes in the global climate. The term \n",
            "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
            "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
            "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
            "contributed to climate change. \n",
            "Historical Context\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "docs_content = [doc.page_content for doc in results]\n",
        "\n",
        "print(\"hypothetical_doc:\\n\")\n",
        "print(text_wrap(hypothetical_doc)+\"\\n\")\n",
        "show_context(docs_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--hyde-hypothetical-document-embedding)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
